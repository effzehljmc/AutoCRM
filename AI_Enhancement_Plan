# Enhanced AI Plan to Showcase & Visualize Results

Note: All SQL queries mentioned in this plan should be executed manually in the SQL editor. But for reference you can find them in the supabase/migrations folder.
Note: Follow @checklist_rules.md when making changes to this plan.

Below is an updated plan that not only implements baseline AI features (RAG, AI calls, suggestions, and agentic stubs) but also incorporates tangible ways to generate and visualize results. This means seeding demo data (tickets, KB articles) and establishing a feedback loop or metrics tracking so teams can validate the AI-assisted features quickly.

Make sure to check all relevant files including the @schema.ts file before proceeding.
---

## Conceptual Overview

This plan implements AI features through several key components, each serving a specific purpose:

1. **RAG Pipeline (Retrieval Augmented Generation)**
   - Why: Enables AI to provide accurate, context-aware responses based on our knowledge base
   - How: Uses vector embeddings to find relevant articles, then uses them to generate responses
   - Key Components: Vector DB, Embeddings, Similarity Search

2. **AI Suggestions**
   - Why: Proactively assists users by suggesting relevant information
   - How: Analyzes user context (tickets, queries) and matches with knowledge base
   - Key Components: Trigger Points, Suggestion Algorithm, Feedback Loop

3. **Metrics and Feedback**
   - Why: Measure effectiveness and improve AI responses over time
   - How: Track user interactions, acceptance rates, and feedback
   - Key Components: Analytics Tables, Feedback Collection, Performance Metrics

---

## Implementation Checklist

### Phase 1: Database Setup 
- [x] Create knowledge base article tables with vector embeddings
- [x] Set up user roles and permissions
- [x] Create functions for storing and retrieving AI suggestions
- [x] Add system user for AI operations
- [x] Test database functions and queries

### Phase 2: Edge Functions Setup
- [x] Create generate-embedding Edge Function
- [x] Create generate-response Edge Function
- [x] Set up environment variables and secrets
- [x] Test match_kb_articles function with embeddings 
  - Verified semantic search works with similarity threshold
  - Successfully retrieves relevant articles
  - Both test and production versions implemented
- [x] Test complete generate-response flow
  - Successfully finds relevant articles
  - Generates AI response using GPT-4
  - Stores suggestions in database with confidence scores
  - Uses system user (4c03221f-179d-4cfd-a62e-a4f68d9a5764)
- [x] Add error handling and logging
  - Added debug logging for environment variables
  - Added error handling for article matching
  - Added error handling for OpenAI API calls
  - Added error handling for database operations

### Phase 3: TypeScript Integration
- [ ] Implement suggestAIResponse in ticket-automation.ts
- [ ] Add types for AI response structure
- [ ] Handle suggestion storage and retrieval

### Phase 4: UI Integration
- [ ] Add AI suggestion component
- [ ] Implement suggestion display logic
- [ ] Add confidence score visualization
- [ ] Add user feedback mechanism
- [ ] Add tests for UI components

### Phase 5: Monitoring and Metrics
- [ ] Add logging for AI operations
- [ ] Track suggestion acceptance rate
- [ ] Monitor response times
- [ ] Set up error tracking
- [ ] Create dashboard for metrics

## Warnings and Notes
1. **API Key Management**: Ensure OPENAI_API_KEY is properly set in environment variables
2. **Rate Limiting**: Monitor OpenAI API usage to avoid hitting limits
3. **Error Handling**: Need robust error handling for API failures
4. **Testing**: Each component needs thorough testing, especially error cases
5. **Performance**: Monitor query performance with larger datasets
6. **Security**: Ensure proper access control for AI features

## Next Steps
[PROGRESS] Edge Functions & Database Integration Complete
- Successfully implemented and tested the complete RAG pipeline
- Edge Functions working with proper error handling and logging
- Database schema updated with ai_suggestions table
- System user (4c03221f-179d-4cfd-a62e-a4f68d9a5764) properly integrated

Next focus will be TypeScript Integration:
1. Create types for AI suggestions and responses
2. Implement suggestAIResponse in ticket-automation.ts
3. Add proper error handling and retries
4. Add suggestion storage and retrieval logic

Current Implementation Details:
1. Database Tables & Functions:
   - ai_suggestions table with proper RLS policies
   - match_kb_articles function with similarity threshold
   - set_updated_at trigger for timestamp management

2. Edge Functions:
   - generate-embedding: Creates embeddings for KB articles
   - generate-response: Full RAG pipeline with GPT-4 integration
   - Environment variables confirmed working:
     - SUPABASE_URL
     - SUPABASE_SERVICE_ROLE_KEY
     - OPENAI_API_KEY

3. Testing Status:
   - Semantic search working (0.5 threshold)
   - GPT-4 integration successful
   - Suggestion storage working
   - Confidence score calculation implemented (0.5-1.0 range)

4. Known Issues:
   - None currently, all critical components working

5. Pending Tasks:
   - TypeScript integration
   - UI components
   - Monitoring and metrics
   - User feedback mechanism

---

## Implementation Steps

### 1. Strengthen the RAG Pipeline
Purpose: Ensure our foundation for AI-powered search and suggestions is solid and efficient.

- [x] Verify KB data and embeddings are valid  
  - [x] Embeddings exist for all KB articles (10 articles verified)
  - [x] Vector search functions properly configured
  - [x] PGVector extension (v0.8.0) confirmed working

- [x] Ensure vector index is in place (e.g., pgvector)  
  - [x] Confirmed pgvector extension is enabled
  - [x] Verified IVFFlat index on embedding column using cosine similarity
  - [x] Index properly configured for efficient vector search

- [x] Confirm RPC or serverless route (match_kb_articles) works as intended  
  - [x] Found embedding generation happens in backend (good architecture)
  - [x] Created Edge Function for embedding generation
  - [x] Updated match_kb_articles to use Edge Function
  - [x] Test end-to-end article matching (Confirmed working with 0.5 similarity threshold)

Implementation Details:
1. Created `/supabase/functions/generate-embedding/index.ts` for OpenAI embedding generation
2. Added shared CORS headers in `_shared/cors.ts`
3. Created migration `20240324000007_update_vector_search.sql` to update the match_kb_articles function
4. Created migration `20240324000009_working_match_kb_articles.sql` with the final working version
5. Successfully tested end-to-end article matching with similarity threshold of 0.5

### 2. Implement AI Suggestions
Purpose: Create an AI-powered system to automatically suggest responses based on ticket content.

Steps:
1. Create Edge Function for Response Generation
   - [x] Create `/supabase/functions/generate-response/index.ts`
   - [x] Use OpenAI to generate contextual responses
   - [x] Include relevant KB articles as context
   - [x] Return structured response with confidence score

2. Update Database Schema
   - [x] Run migration `20240324000009_working_match_kb_articles.sql` in SQL editor
   - [ ] Run corrected migration `20240324000010_add_ai_suggestions.sql` in SQL editor (now using profiles table)
   - [ ] Verify schema changes with test queries:

```sql
-- Test 1: Verify match_kb_articles function (Already working)
select * from match_kb_articles(
  'How do I export my data?',
  'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im1jcXlkcW1xdW5kYnpuaWVkYmNqIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTczNzI3NjMzOSwiZXhwIjoyMDUyODUyMzM5fQ.M96x8QzbEEsegD85uYEg7lmgRTsQIRU6p0CIvlpCKw0',
  0.5,
  3
);

-- Test 2: Get or create system user
select get_or_create_ai_system_user() as system_user_id;

-- Test 3: Verify system user exists
select id, email, full_name 
from profiles 
where id = (select get_or_create_ai_system_user());

-- Test 4: Store an AI suggestion
select store_ai_suggestion(
  '6004f08d-3a3c-4151-b3e0-3b790c75fd6c'::uuid,
  'Based on our knowledge base, here is how you can export your data. You can create custom reports in various formats (CSV, JSON, PDF), set up scheduled reports for automation, and utilize data visualization tools. For detailed steps, please refer to our Data Export Guide.',
  0.85,
  '{"model": "gpt-4", "used_articles": ["Data Export and Reporting"], "similarity_scores": [0.622]}'::jsonb
);

-- Test 5: Retrieve AI suggestions for a ticket
select * from get_ticket_ai_suggestions(
  '6004f08d-3a3c-4151-b3e0-3b790c75fd6c'::uuid,
  5
);

-- Test 6: Verify ticket_messages table changes
select 
  tm.id,
  tm.message_type,
  tm.confidence_score,
  tm.metadata,
  tm.created_at,
  p.email as author_email
from ticket_messages tm
join profiles p on tm.user_id = p.id
where tm.message_type = 'auto_suggestion'
order by tm.created_at desc
limit 5;
```

3. Create TypeScript Integration
   - [ ] Implement suggestAIResponse in ticket-automation.ts
   - [ ] Add types for AI response structure
   - [ ] Handle suggestion storage and retrieval

4. Testing and Validation
   - [ ] Create sample tickets with varied scenarios
   - [ ] Test response generation with different contexts
   - [ ] Validate suggestion quality and relevance

Next Steps:
1. Execute the SQL migrations in the SQL editor to update the schema
2. Verify the changes by testing the new functions
3. Proceed with TypeScript integration

Would you like me to provide the SQL queries that need to be run in the SQL editor?

### 3. Set Up Baseline AI Calls

- [ ] Create a serverless "generateResponse" endpoint  
  - [ ] Return a typed JSON payload with the AI-generated response.  
  - [ ] Log request/response data for debugging and demonstration.

- [ ] Securely store and manage AI provider credentials  
  - [ ] Use environment variables; never hardcode the API key.  

- [ ] Implement minimal testing to validate the endpoint  
  - [ ] Write a small unit test that mocks an AI response and checks for a proper JSON structure.  
  - [ ] Compare logged requests/responses for debugging.

### Demonstration Data
- [ ] Create a script (e.g., scripts/seedTicketData.ts) that inserts sample tickets with varied contexts into "tickets."  
  - For instance:  
    ```typescript:path/to/scripts/seedTicketData.ts
    import { supabase } from '@/lib/supabase';

    async function seedTicketData() {
      const sampleTickets = [
        {
          title: 'Billing Error on Invoice #1234',
          description: 'I was charged twice for the same invoice. Please assist.',
          status: 'new'
        },
        {
          title: 'Unable to Access My Premium Features',
          description: 'I upgraded my plan, but the new features are locked.',
          status: 'new'
        }
      ];

      const { data, error } = await supabase
        .from('tickets')
        .insert(sampleTickets)
        .select();

      if (error) {
        console.error('Error seeding ticket data:', error);
      } else {
        console.log('Successfully seeded tickets:', data);
      }
    }

    seedTicketData();
    ```
  - [ ] Run this script to quickly create 2–3 tickets that can demonstrate the AI calls.  

---

## 4. Expand "onTicketCreated" with AI Suggestions

- [ ] Integrate new AI call (suggestAIResponse) in ticket-automation.ts  
  - [ ] After creating or updating a ticket, call "generateResponse" to produce a suggested reply.  
  - [ ] Pass top KB articles as context.  

- [ ] Insert AI-generated message into ticket_messages as "auto_suggestion"  
  - [ ] Verify the new "auto_suggestion" row in "ticket_messages" and see the actual text.  

### See It in Action
- [ ] Open the newly seeded tickets in your UI (e.g., "TicketDetail")  
  - [ ] Confirm an "AI Suggestion" message is posted.  
  - [ ] Log or display in the console the AI's recommended response text.  

---

## 5. Introduce Basic "Agentic" Concepts

- [ ] Create a stub for ticket classification (classifyTicket)  
  - [ ] Accepts a ticket description; returns a category (billing, account, tech, etc.).  
  - [ ] For now, log the classification result.  

- [ ] Prepare "agentInterfaces.ts" with placeholders for future external API calls  
  - [ ] For demonstration, add a mock "checkCRM" or "checkShipping" function that logs a placeholder message.

- [ ] Add an optional "ai_metadata" column to "tickets"  
  - [ ] Store classification or other agentic data (e.g., "confidence" or "next steps").  
  - [ ] View these in your DB after classification for clarity.

---

## 6. Refine, Test & Monitor

- [PROGRESS] Write or update unit tests for new AI-related functions  
  - [ ] Tests for "generateResponse" endpoint.  
  - [ ] Tests for "classifyTicket" logic.  

- [ ] Gather agent feedback on AI suggestions  
  - [ ] Provide a UI toggle or a quick rating system so agents can up/downvote AI responses.  
  - [ ] Store feedback in a "ai_feedback" table.  

- [ ] Track usage metrics (acceptance rate, classification accuracy, etc.)  
  - [ ] Provide a minimal "Metrics" dashboard to showcase how often AI-suggested replies were accepted vs. edited.

### Showcase Example
1. **Seed** a set of sample tickets via "seedTicketData.ts."  
2. **Check** the console or your dashboard to confirm each ticket triggers "suggestAIResponse."  
3. **Review** the "ticket_messages" table or UI to see "auto_suggestion."  
4. **Record** a rating or acceptance in your new "ai_feedback" table.

---

## 7. Path to Full Agentic AI

- [ ] Implement classification-driven routing (auto-priority, team assignment)  
  - [ ] If classification is "billing," set ticket priority to "high" and assign to "Billing Team."  
  - [ ] Let the agent confirm or override this.  

- [ ] Connect "agentInterfaces.ts" to real external tools (CRM, shipping, etc.)  
  - [ ] Ensure correct API credentials and authentication flows.  
  - [ ] Log and visualize calls for demonstration (e.g., "CRM check succeeded for customer #C123").  

- [ ] Ensure permissioning and safety checks for AI-initiated actions  
  - [ ] Restrict which external APIs the AI can invoke without human approval.  

---

## Warnings

- Integrating external APIs can raise significant security or compliance tasks.  
- Large volume AI usage may be costly; set usage monitoring and billing alerts.  
- Over-reliance on AI suggestions without human verification can lead to inaccuracies.  

### Verification
- in order to verify that you read this plan, include an 🐧 emoji in your reply.